{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load all of our images into two lists, for our classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_imgs = []\n",
    "\n",
    "for data_group in ['train', 'test']:\n",
    "    imgs = os.listdir(f'open/{data_group}')\n",
    "    for img_name in imgs:\n",
    "        if img_name[-4:] == '.jpg':\n",
    "            open_imgs.append(img_to_array(load_img(f'open/{data_group}/{img_name}')))\n",
    "            \n",
    "open_imgs = np.array(open_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_imgs = []\n",
    "\n",
    "imgs = os.listdir('close')\n",
    "for img_name in imgs:\n",
    "    if img_name[-4:] == '.jpg':\n",
    "        close_imgs.append(img_to_array(load_img(f'close/{img_name}')))\n",
    "        \n",
    "close_imgs = np.array(close_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 400, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_imgs[14].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create an with all of our images, flatten it and rescale it for better performance of our neural\n",
    "network. We also need the corresponding labels array (0 if closed, 1 if open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = np.concatenate([open_imgs, close_imgs])\n",
    "\n",
    "labels = np.array([1 for i in range(len(open_imgs))] + [0 for i in range(len(close_imgs))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split our dataset between training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_imgs, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our model, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "             TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
    "\n",
    "def model_clf(input_size, n_units = 20, n_hidden_layers = 1):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(260,400,1)))\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Before going into layer C5, we flatten our units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(units=120, activation='relu'))\n",
    "    # Layer F6\n",
    "    model.add(Dense(units=84, activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=10, activation = 'sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_clf(X_train.shape[1])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                6240020   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 6,240,461\n",
      "Trainable params: 6,240,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.7147 - accuracy: 0.3750WARNING:tensorflow:From /home/romaincaplier/.pyenv/versions/3.7.6/envs/vivadata/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 2.5799 - accuracy: 0.4731 - val_loss: 1.0411 - val_accuracy: 0.3407\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.8196 - accuracy: 0.5228 - val_loss: 1.1642 - val_accuracy: 0.3626\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.9273 - accuracy: 0.5572 - val_loss: 0.9228 - val_accuracy: 0.5934\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6648 - accuracy: 0.7159 - val_loss: 0.5057 - val_accuracy: 0.8462\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.4938 - accuracy: 0.7890 - val_loss: 0.4248 - val_accuracy: 0.8846\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.4223 - accuracy: 0.8441 - val_loss: 0.5653 - val_accuracy: 0.7198\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.4058 - accuracy: 0.8428 - val_loss: 0.3843 - val_accuracy: 0.8846\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.3436 - accuracy: 0.8786 - val_loss: 0.4124 - val_accuracy: 0.9011\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.3520 - accuracy: 0.8800 - val_loss: 0.5505 - val_accuracy: 0.7473\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.4033 - accuracy: 0.8359 - val_loss: 0.4381 - val_accuracy: 0.8077\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.3440 - accuracy: 0.8772 - val_loss: 0.3454 - val_accuracy: 0.8901\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.3734 - accuracy: 0.8676 - val_loss: 0.3642 - val_accuracy: 0.9286\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.3010 - accuracy: 0.8966 - val_loss: 0.3358 - val_accuracy: 0.8846\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2661 - accuracy: 0.9186 - val_loss: 0.3940 - val_accuracy: 0.8297\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2858 - accuracy: 0.9062 - val_loss: 0.4627 - val_accuracy: 0.7802\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2752 - accuracy: 0.8979 - val_loss: 0.3321 - val_accuracy: 0.8516\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2698 - accuracy: 0.9076 - val_loss: 0.4850 - val_accuracy: 0.8736\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2793 - accuracy: 0.8910 - val_loss: 0.3810 - val_accuracy: 0.8187\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2161 - accuracy: 0.9283 - val_loss: 0.2676 - val_accuracy: 0.9341\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1971 - accuracy: 0.9517 - val_loss: 0.2634 - val_accuracy: 0.9341\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1933 - accuracy: 0.9434 - val_loss: 0.2779 - val_accuracy: 0.9451\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1943 - accuracy: 0.9531 - val_loss: 0.2644 - val_accuracy: 0.9231\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2615 - accuracy: 0.8869 - val_loss: 0.4948 - val_accuracy: 0.8681\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.5467 - accuracy: 0.7862 - val_loss: 0.5158 - val_accuracy: 0.8956\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2377 - accuracy: 0.9131 - val_loss: 0.2605 - val_accuracy: 0.9341\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1974 - accuracy: 0.9283 - val_loss: 0.3567 - val_accuracy: 0.9176\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2039 - accuracy: 0.9241 - val_loss: 0.3205 - val_accuracy: 0.9396\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2077 - accuracy: 0.9255 - val_loss: 0.2772 - val_accuracy: 0.9451\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1427 - accuracy: 0.9641 - val_loss: 0.2458 - val_accuracy: 0.9396\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1340 - accuracy: 0.9669 - val_loss: 0.2482 - val_accuracy: 0.9396\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1268 - accuracy: 0.9683 - val_loss: 0.2269 - val_accuracy: 0.9505\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1286 - accuracy: 0.9697 - val_loss: 0.2443 - val_accuracy: 0.9286\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1366 - accuracy: 0.9586 - val_loss: 0.2335 - val_accuracy: 0.9286\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1414 - accuracy: 0.9586 - val_loss: 0.2278 - val_accuracy: 0.9396\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1124 - accuracy: 0.9793 - val_loss: 0.2568 - val_accuracy: 0.9341\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.1096 - accuracy: 0.9779 - val_loss: 0.2210 - val_accuracy: 0.9451\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1077 - accuracy: 0.9821 - val_loss: 0.2478 - val_accuracy: 0.9341\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.1118 - accuracy: 0.9793 - val_loss: 0.3353 - val_accuracy: 0.9231\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1229 - accuracy: 0.9669 - val_loss: 0.2004 - val_accuracy: 0.9560\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0990 - accuracy: 0.9821 - val_loss: 0.2045 - val_accuracy: 0.9396\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0983 - accuracy: 0.9821 - val_loss: 0.1932 - val_accuracy: 0.9560\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0966 - accuracy: 0.9779 - val_loss: 0.1950 - val_accuracy: 0.9505\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0985 - accuracy: 0.9807 - val_loss: 0.2177 - val_accuracy: 0.9231\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0982 - accuracy: 0.9779 - val_loss: 0.1914 - val_accuracy: 0.9560\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0903 - accuracy: 0.9848 - val_loss: 0.2062 - val_accuracy: 0.9341\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0914 - accuracy: 0.9834 - val_loss: 0.1890 - val_accuracy: 0.9560\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0846 - accuracy: 0.9848 - val_loss: 0.2070 - val_accuracy: 0.9231\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0910 - accuracy: 0.9834 - val_loss: 0.2010 - val_accuracy: 0.9341\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0855 - accuracy: 0.9834 - val_loss: 0.1901 - val_accuracy: 0.9396\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0810 - accuracy: 0.9834 - val_loss: 0.2003 - val_accuracy: 0.9286\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0837 - accuracy: 0.9821 - val_loss: 0.1776 - val_accuracy: 0.9560\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0775 - accuracy: 0.9876 - val_loss: 0.1891 - val_accuracy: 0.9560\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0690 - accuracy: 0.9862 - val_loss: 0.2163 - val_accuracy: 0.9231\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0816 - accuracy: 0.9876 - val_loss: 0.1808 - val_accuracy: 0.9505\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0650 - accuracy: 0.9903 - val_loss: 0.1773 - val_accuracy: 0.9505\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0630 - accuracy: 0.9931 - val_loss: 0.1735 - val_accuracy: 0.9505\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0619 - accuracy: 0.9903 - val_loss: 0.1897 - val_accuracy: 0.9505\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0579 - accuracy: 0.9917 - val_loss: 0.1729 - val_accuracy: 0.9505\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0585 - accuracy: 0.9903 - val_loss: 0.2278 - val_accuracy: 0.9451\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0699 - accuracy: 0.9876 - val_loss: 0.2227 - val_accuracy: 0.9505\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0862 - accuracy: 0.9779 - val_loss: 0.3254 - val_accuracy: 0.9176\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1000 - accuracy: 0.9738 - val_loss: 0.2133 - val_accuracy: 0.9505\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0757 - accuracy: 0.9807 - val_loss: 0.1907 - val_accuracy: 0.9560\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0752 - accuracy: 0.9821 - val_loss: 0.1862 - val_accuracy: 0.9560\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0521 - accuracy: 0.9890 - val_loss: 0.1768 - val_accuracy: 0.9451\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0534 - accuracy: 0.9917 - val_loss: 0.1962 - val_accuracy: 0.9505\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0478 - accuracy: 0.9917 - val_loss: 0.1949 - val_accuracy: 0.9451\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0495 - accuracy: 0.9931 - val_loss: 0.1708 - val_accuracy: 0.9560\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0466 - accuracy: 0.9945 - val_loss: 0.2338 - val_accuracy: 0.9451\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0685 - accuracy: 0.9890 - val_loss: 0.1733 - val_accuracy: 0.9505\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0606 - accuracy: 0.9862 - val_loss: 0.3070 - val_accuracy: 0.9231\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0526 - accuracy: 0.9945 - val_loss: 0.1817 - val_accuracy: 0.9505\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0479 - accuracy: 0.9917 - val_loss: 0.1658 - val_accuracy: 0.9560\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0415 - accuracy: 0.9959 - val_loss: 0.1611 - val_accuracy: 0.9615\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0384 - accuracy: 0.9959 - val_loss: 0.1644 - val_accuracy: 0.9560\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0396 - accuracy: 0.9959 - val_loss: 0.1731 - val_accuracy: 0.9560\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0396 - accuracy: 0.9945 - val_loss: 0.1557 - val_accuracy: 0.9560\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0473 - accuracy: 0.9917 - val_loss: 0.1944 - val_accuracy: 0.9451\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0364 - accuracy: 0.9972 - val_loss: 0.1516 - val_accuracy: 0.9615\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0364 - accuracy: 0.9972 - val_loss: 0.2545 - val_accuracy: 0.9341\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0449 - accuracy: 0.9917 - val_loss: 0.1611 - val_accuracy: 0.9615\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0493 - accuracy: 0.9876 - val_loss: 0.1561 - val_accuracy: 0.9615\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0357 - accuracy: 0.9972 - val_loss: 0.1577 - val_accuracy: 0.9560\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0394 - accuracy: 0.9959 - val_loss: 0.1790 - val_accuracy: 0.9560\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0309 - accuracy: 0.9972 - val_loss: 0.1681 - val_accuracy: 0.9505\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0305 - accuracy: 0.9972 - val_loss: 0.1649 - val_accuracy: 0.9560\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0309 - accuracy: 0.9972 - val_loss: 0.1683 - val_accuracy: 0.9560\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0295 - accuracy: 0.9972 - val_loss: 0.1533 - val_accuracy: 0.9615\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0322 - accuracy: 0.9972 - val_loss: 0.1777 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe01414c290>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree('./Graph')\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          epochs=500, \n",
    "          batch_size=64, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now improve our medels, as we can see some overfitting (99.7% on train set vs 95.6% on the test set). To solve that issue, we will add layers of regularization to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_clf_regul_drop(input_size, n_units = 20, n_hidden_layers = 1, regul = 0, dropout = 0.2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(n_units, input_dim=input_size, activation='relu'))\n",
    "    \n",
    "    for i in range(n_hidden_layers):\n",
    "        model.add(Dense(n_units, activation='relu', kernel_regularizer=regularizers.l2(regul)))\n",
    "        model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regul_drop = model_clf_regul_drop(X_train.shape[1], n_units = 50, n_hidden_layers = 2, regul = 0, dropout = 0.5)\n",
    "model_regul_drop.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 50)                15600050  \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,605,201\n",
      "Trainable params: 15,605,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regul_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 2/12 [====>.........................] - ETA: 1s - loss: 1.0719 - accuracy: 0.5547WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0566s vs `on_train_batch_begin` time: 0.1632s). Check your callbacks.\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 0.9292 - accuracy: 0.5531 - val_loss: 0.6899 - val_accuracy: 0.6374\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.6907 - accuracy: 0.6028 - val_loss: 0.6872 - val_accuracy: 0.6374\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6873 - accuracy: 0.6138 - val_loss: 0.6844 - val_accuracy: 0.6374\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6848 - accuracy: 0.6138 - val_loss: 0.6815 - val_accuracy: 0.6374\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6828 - accuracy: 0.6138 - val_loss: 0.6790 - val_accuracy: 0.6374\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.6814 - accuracy: 0.6138 - val_loss: 0.6767 - val_accuracy: 0.6374\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.6793 - accuracy: 0.6138 - val_loss: 0.6748 - val_accuracy: 0.6374\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6775 - accuracy: 0.6138 - val_loss: 0.6731 - val_accuracy: 0.6374\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6778 - accuracy: 0.6138 - val_loss: 0.6717 - val_accuracy: 0.6374\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6760 - accuracy: 0.6138 - val_loss: 0.6703 - val_accuracy: 0.6374\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6748 - accuracy: 0.6138 - val_loss: 0.6689 - val_accuracy: 0.6374\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6746 - accuracy: 0.6138 - val_loss: 0.6678 - val_accuracy: 0.6374\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.6738 - accuracy: 0.6138 - val_loss: 0.6667 - val_accuracy: 0.6374\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6721 - accuracy: 0.6138 - val_loss: 0.6656 - val_accuracy: 0.6374\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6711 - accuracy: 0.6138 - val_loss: 0.6647 - val_accuracy: 0.6374\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6711 - accuracy: 0.6138 - val_loss: 0.6641 - val_accuracy: 0.6374\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6711 - accuracy: 0.6138 - val_loss: 0.6635 - val_accuracy: 0.6374\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6711 - accuracy: 0.6138 - val_loss: 0.6628 - val_accuracy: 0.6374\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6715 - accuracy: 0.6138 - val_loss: 0.6622 - val_accuracy: 0.6374\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6697 - accuracy: 0.6138 - val_loss: 0.6616 - val_accuracy: 0.6374\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6702 - accuracy: 0.6138 - val_loss: 0.6611 - val_accuracy: 0.6374\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6689 - accuracy: 0.6138 - val_loss: 0.6607 - val_accuracy: 0.6374\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6694 - accuracy: 0.6138 - val_loss: 0.6602 - val_accuracy: 0.6374\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6709 - accuracy: 0.6138 - val_loss: 0.6599 - val_accuracy: 0.6374\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6695 - accuracy: 0.6138 - val_loss: 0.6597 - val_accuracy: 0.6374\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6681 - accuracy: 0.6138 - val_loss: 0.6594 - val_accuracy: 0.6374\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6675 - accuracy: 0.6138 - val_loss: 0.6591 - val_accuracy: 0.6374\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6672 - accuracy: 0.6138 - val_loss: 0.6590 - val_accuracy: 0.6374\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6689 - accuracy: 0.6138 - val_loss: 0.6587 - val_accuracy: 0.6374\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6689 - accuracy: 0.6138 - val_loss: 0.6586 - val_accuracy: 0.6374\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6665 - accuracy: 0.6138 - val_loss: 0.6584 - val_accuracy: 0.6374\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.6691 - accuracy: 0.6138 - val_loss: 0.6582 - val_accuracy: 0.6374\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.6677 - accuracy: 0.6138 - val_loss: 0.6580 - val_accuracy: 0.6374\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.6662 - accuracy: 0.6138 - val_loss: 0.6578 - val_accuracy: 0.6374\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6701 - accuracy: 0.6138 - val_loss: 0.6577 - val_accuracy: 0.6374\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6672 - accuracy: 0.6138 - val_loss: 0.6575 - val_accuracy: 0.6374\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.6672 - accuracy: 0.6138 - val_loss: 0.6574 - val_accuracy: 0.6374\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6677 - accuracy: 0.6138 - val_loss: 0.6573 - val_accuracy: 0.6374\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6684 - accuracy: 0.6138 - val_loss: 0.6572 - val_accuracy: 0.6374\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6678 - accuracy: 0.6138 - val_loss: 0.6570 - val_accuracy: 0.6374\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6680 - accuracy: 0.6138 - val_loss: 0.6570 - val_accuracy: 0.6374\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6689 - accuracy: 0.6138 - val_loss: 0.6570 - val_accuracy: 0.6374\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6677 - accuracy: 0.6138 - val_loss: 0.6570 - val_accuracy: 0.6374\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.6689 - accuracy: 0.6138 - val_loss: 0.6571 - val_accuracy: 0.6374\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6671 - accuracy: 0.6138 - val_loss: 0.6572 - val_accuracy: 0.6374\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6676 - accuracy: 0.6138 - val_loss: 0.6572 - val_accuracy: 0.6374\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.6692 - accuracy: 0.6138 - val_loss: 0.6571 - val_accuracy: 0.6374\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.6684 - accuracy: 0.6138 - val_loss: 0.6572 - val_accuracy: 0.6374\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.6667 - accuracy: 0.6138 - val_loss: 0.6571 - val_accuracy: 0.6374\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6668 - accuracy: 0.6138 - val_loss: 0.6571 - val_accuracy: 0.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf542d21d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regul_drop.fit(x=X_train, \n",
    "                     y=y_train, \n",
    "                     validation_data=(X_test, y_test), \n",
    "                     epochs=500, \n",
    "                     batch_size=64, \n",
    "                     callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
